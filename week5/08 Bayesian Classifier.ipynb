{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Ling-Spam dataset](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex6/ex6.html)\n",
    "  * Preprocessed\n",
    "* [Bag of Words](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "  * CountVectorizer\n",
    "    * binary=True\n",
    "* [Multinomial vs Bernoulli Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "* [20 Newsgroups](http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bayesian Classification\n",
    "\n",
    "So far we've covered linear regression which is handy for predicting a Y given an X or any multitude of variables. Unfortunately we don't always want to predict an indeterminate outcome given an input - sometimes we will want to find out what category something will fall into. Spam filters do this all of the time.\n",
    "\n",
    "The way it works is that your spam filter has seen a lot of spam - more than any human should have to - and it's been told what spam looks like and how to find more spam. Doing this feeds it's hunger for more spam. The more spam it reads and is validated the better it gets.\n",
    "This is using a Bayesian method of classification where it strengthens (or weakens) it's belief in a probability to be true (or false) given any amount of data.\n",
    "\n",
    "Take our coin flip for example. With an unbiased coin we may get somewhat crazy data with a tiny data set, but with millions of flips - we are able to accurately predict the probability that a heads or tails outcome will occur.\n",
    "\n",
    "In our case, we want to classify a message as spam or not spam given a strong history of learning what spam looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This handy function will help us read in our data quickly. Since we have a lot of spam (and not spam) we want to train our prediction models well. So we want to load in our training spam/not-spam files as well as our testing spam/not-spam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ling_spam(directory):\n",
    "    files = glob.glob(\"ling-spam/{}/*.txt\".format(directory))\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(file) as fh:\n",
    "            texts.append(fh.read())\n",
    "    return texts\n",
    "\n",
    "spam_train = read_ling_spam(\"spam-train\")\n",
    "non_spam_train = read_ling_spam(\"nonspam-train\")\n",
    "spam_test = read_ling_spam(\"spam-test\")\n",
    "non_spam_test = read_ling_spam(\"nonspam-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great parttime summer job display box credit application need place small owneroperate store area here introduce yourself store owner manager our effective script tell little display box save customer hundred dollar draw card business every app send spot counter place box nothing need need name address company send commission check compensaation every box place become representative earn commission each application store course much profitable plan pay month small effort call code hours receive detail removed our mailing list type b hotmail com area remove subject area e mail send '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A count vectorizer will tokenize a corpus of text and produce a matrix of counts for the given words.\n",
    "\n",
    "Read more on CounterVectorizer [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate our vectorizer just the same as we have before with our Linear Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the .fit() method with our combined non-spam and spam training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(spam_train + non_spam_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and extrapolate our transformed training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(non_spam_train + spam_train)\n",
    "y_train = ['non-spam'] * len(non_spam_train) + ['spam'] * len(spam_train)\n",
    "X_test = vectorizer.transform(non_spam_test + spam_test)\n",
    "y_test = ['non-spam'] * len(non_spam_test) + ['spam'] * len(spam_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our X_train creates what is called a `sparse matrix`\n",
    "\n",
    "> In numerical analysis, a sparse matrix is a matrix in which most of the elements are zero. By contrast, if most of the elements are nonzero, then the matrix is considered dense. The fraction of zero elements over the total number of elements in a matrix is called the sparsity (density). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_train will label a corelated message as spam or not spam. Imagine this as a label for a message in the same index on the `X_train` sparse matrix.\n",
    "\n",
    "Lets get a few of the feature names by slicing the array we get back from `vectorizer.get_feature_names()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['armidale',\n",
       " 'armin',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arnagardur',\n",
       " 'arnhem',\n",
       " 'arnold',\n",
       " 'aron',\n",
       " 'aronoff',\n",
       " 'around']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compare the lengths of our training data vs. the amount of features our vectorizer has created for us we can print the lengths.\n",
    "\n",
    "Notice quite a big difference between the two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 19073\n"
     ]
    }
   ],
   "source": [
    "print(len(spam_train + non_spam_train), len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can use MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our X and Y data to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99857142857142855"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ooops\n",
    "\n",
    "*What did we do wrong?*\n",
    "\n",
    "We compared our model to the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97692307692307689"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all! 97% accuracy for spam prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when we pass messages in to our prediction function it will give us an answer - and remember, with 97% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = [\"Hi, Bekk how are you?  I am great did you get that message I sent you?\"]\n",
    "transormed_message = vectorizer.transform(message)\n",
    "\n",
    "classifier.predict(transormed_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Pipelines](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline is a simple way to create a transformation pipeline for our data.\n",
    "\n",
    "If you noticed above we had do do a few steps before we were able to adequate score our prediction model.\n",
    "\n",
    " - We had to vectorize the corpus\n",
    " - We had to transform the vectorized data\n",
    " - We had to fit our Multinomian Naive Bayes classifier to our data\n",
    " \n",
    "What if I told you there was a way you could create a pipeline for all of those to be done in one step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_map = [('bag_of_words', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('bayes', MultinomialNB())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets pass our `pipeline_map` into our `Pipeline` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(pipeline_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still require our `y_train` data, if you remember was our spam/no spam labels.\n",
    "\n",
    "Lets fit our combined spam/non-spam training data and our `y_train` information to our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag_of_words', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "     ...ear_tf=False, use_idf=True)), ('bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(non_spam_train + spam_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after all of that, we can pass our `non_spam_test` data set into our vectorized-transformed-classified model and get back the information we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipeline.predict(non_spam_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lectureship linguistic s c h o o l o f e n g l s h n d l n g u s t c s u n v e r s t y o f d u r h m lecturer generative linguistics successful candidate must complete process complete doctorate must able demonstrate strong research focus historical linguistics phonology syntax romance linguistics vium dissertation publish work area ability teach sociolinguistic advantage post tenable october salary within range pound per annum lecturer grade scale accord experience further detail obtain personnel officer old shire hall university durham durham dh hp unite kingdom tel fax whom application send later please quote reference a '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_spam_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-spam'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"Excuse me buddy. So, you're a cadet, your studying. What's your focus? Xenolinguistics. You have no idea what that means. The study of alien languages. Morphology, phonology, syntax. Means you've got a talented tongue.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam', 'spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'spam', 'spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'spam', 'spam', 'non-spam',\n",
       "       'non-spam', 'spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam', 'spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam', 'non-spam',\n",
       "       'non-spam', 'non-spam', 'non-spam', 'non-spam'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(non_spam_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96923076923076923"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(non_spam_test + spam_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
